{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1996fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense, Masking\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "# 1. Charger les donn√©es CSV\n",
    "df = pd.read_csv(\"Standardize.csv\", header=None)\n",
    "df.columns = ['user', 'gesture', 'repetition', 'x', 'y', 'z', 't']\n",
    "\n",
    "# 2. Regrouper par (user, gesture, repetition)\n",
    "grouped = df.groupby(['user', 'gesture', 'repetition'])\n",
    "with open(\"Standardize.csv\", 'r') as file:\n",
    "    for line in file:\n",
    "        pass\n",
    "    \n",
    "sequences = {}\n",
    "gesture_groups = []\n",
    "gesture_group = []\n",
    "for i in range(10):\n",
    "\n",
    "    for (user, gesture, repetition), group in grouped:\n",
    "        if gesture != \"gesture\":\n",
    "            if i == int(gesture):\n",
    "                gesture_group.append(group)\n",
    "    gesture_groups.append(gesture_group)\n",
    "    gesture_group=[]\n",
    "\n",
    "\n",
    "for i in range(10):  # 10 gestes\n",
    "    for j in range(len(gesture_groups[i])):  # nombre de r√©p√©titions\n",
    "        sequence = []\n",
    "        for row in gesture_groups[i][j].itertuples(index=False):\n",
    "            sequence.append([row.user, row.gesture, row.repetition, row.x, row.y, row.z, row.t])\n",
    "        gesture_groups[i][j] = sequence  # remplacement du DataFrame par la liste de lignes\n",
    "\n",
    "print(len(gesture_groups[1][1]))\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Masking, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# √âtape 1 ‚Äî Trouver la longueur maximale globale\n",
    "max_len = max(len(seq) for gesture in gesture_groups for seq in gesture)\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "# √âtape 2 ‚Äî Interpolation + extraction des features x,y,z,t\n",
    "for gesture_id in range(10):\n",
    "    for sequence in gesture_groups[gesture_id]:\n",
    "        seq_array = np.array(sequence)\n",
    "        original_len = seq_array.shape[0]\n",
    "\n",
    "        original_indices = np.linspace(0, 1, original_len)\n",
    "        target_indices = np.linspace(0, 1, max_len)\n",
    "\n",
    "        interpolated_features = []\n",
    "        for col in range(3, 7):  # x, y, z, t\n",
    "            interpolated_col = np.interp(target_indices, original_indices, seq_array[:, col].astype(float))\n",
    "            interpolated_features.append(interpolated_col)\n",
    "\n",
    "        interpolated_seq = np.stack(interpolated_features, axis=1)  # shape: (max_len, 4)\n",
    "        X.append(interpolated_seq)\n",
    "        y.append(gesture_id)\n",
    "\n",
    "X = np.array(X)  # shape: (n_samples, max_len, 4)\n",
    "y = np.array(y)\n",
    "\n",
    "# √âtape 3 ‚Äî Standardisation des donn√©es x,y,z,t (individuellement par colonne)\n",
    "# Flatten, scale, reshape\n",
    "X_reshaped = X.reshape(-1, 4)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_reshaped)\n",
    "X = X_scaled.reshape(X.shape)  # back to (n_samples, max_len, 4)\n",
    "\n",
    "# √âtape 4 ‚Äî Encodage + Split\n",
    "y = to_categorical(y, num_classes=10)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Construction du mod√®le am√©lior√©\n",
    "# Construction du mod√®le surpuissant\n",
    "model = Sequential()\n",
    "model.add(Masking(mask_value=0., input_shape=(max_len, 4)))\n",
    "model.add(LSTM(512, return_sequences=True))  # üß† tr√®s gros LSTM\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256, return_sequences=True))  # üß† deuxi√®me gros LSTM\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entra√Ænement sans EarlyStopping\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=100,              # üî• 100 epochs complets\n",
    "    batch_size=16,\n",
    "    validation_split=0.1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Pr√©dictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Matrice de confusion\n",
    "cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "totals = cm.sum(axis=1)\n",
    "\n",
    "for indexi, i in enumerate(cm):\n",
    "    for indexj, j in enumerate(cm[indexi]):\n",
    "        cm[indexi][indexj] = j / (totals[indexi]) * 100\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(xticks_rotation=45, cmap=\"Blues\")\n",
    "plt.xlabel(\"Pr√©dit\")\n",
    "plt.ylabel(\"R√©el\")\n",
    "plt.title(\"Matrice de confusion en pourcentages (%) ‚Äî mod√®le tr√®s puissant\")\n",
    "plt.show()\n",
    "\n",
    "# Courbes d'apprentissage (Accuracy et Loss)\n",
    "plt.figure(figsize=(12,5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Accuracy au cours des epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Loss au cours des epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
